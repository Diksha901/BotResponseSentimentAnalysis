{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kkXpLZ09LG2U"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7uIAWAOxL3ku",
    "outputId": "6d2231ba-61a7-4850-9599-91a3d1ea425f"
   },
   "outputs": [],
   "source": [
    "teen_mental_health_df=pd.read_csv('/content/final_teen_mental_health_chatbot_dataset.csv')\n",
    "print(teen_mental_health_df.head())\n",
    "print(\"**************************\")\n",
    "print(f\"The shape of the dataset is : {teen_mental_health_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RFVSQTJgMaFg",
    "outputId": "d1da1a5f-1892-4ddc-b9e8-99a4e7513eb8"
   },
   "outputs": [],
   "source": [
    "teen_mental_health_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sevN6XmSNF8c",
    "outputId": "a4bbc818-e66c-4813-95f4-ce7b6a278df6"
   },
   "outputs": [],
   "source": [
    "print(teen_mental_health_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25JgaqGZTldH"
   },
   "source": [
    "# **Text Preprocessing**\n",
    "* Converting to lowercase\n",
    "* Removal of Stopwords\n",
    "* Lemmatization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GA6FQTH3Vr_t",
    "outputId": "1f7c2bf4-141c-45e8-9ae9-df0957954310"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 633
    },
    "id": "l8PrrRB61FWY",
    "outputId": "6a0d5d0b-9091-4ec0-ea4b-7c0bc404f857"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(teen_mental_health_df['user_input']))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud for User Input ')\n",
    "plt.show()\n",
    "print(\"*\"*80)\n",
    "print(\"-\"*80)\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(teen_mental_health_df['bot_response']))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud for Bot Response ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RL5E8WsF1rJQ",
    "outputId": "a475be70-fc85-4409-bff5-ea98838b4dc8"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    tokens = word_tokenize(text)\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "\n",
    "    return \" \".join(cleaned_tokens)\n",
    "\n",
    "\n",
    "teen_mental_health_df[\"cleaned_user_input\"] = teen_mental_health_df[\"user_input\"].apply(preprocess_text)\n",
    "teen_mental_health_df[\"cleaned_bot_response\"]=teen_mental_health_df[\"bot_response\"].apply(preprocess_text)\n",
    "\n",
    "print(teen_mental_health_df[[\"user_input\", \"cleaned_user_input\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jN0BxNhLW19D",
    "outputId": "3c179dd3-63e8-4be9-dbb0-4a4fdbaea9f6"
   },
   "outputs": [],
   "source": [
    "print(teen_mental_health_df['cleaned_bot_response'].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X59cdZfs76Fu",
    "outputId": "db3e9257-8856-4008-ba4d-bc5eb0a8d797"
   },
   "outputs": [],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aCZIz0x48NlP"
   },
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "def frequent_words(df, col, top_n=20):\n",
    "    all_words = []\n",
    "    for text in df[col]:\n",
    "        words = word_tokenize(text)\n",
    "        all_words.extend(words)\n",
    "\n",
    "    word_freq = FreqDist(all_words)\n",
    "    return word_freq.most_common(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "qLjPc8f59QS3",
    "outputId": "6a3f315e-81dc-4e5b-b89b-9c5ec3aecd9b"
   },
   "outputs": [],
   "source": [
    "def plot_frequent_words(df, col, top_n=20):\n",
    "    top_words = frequent_words(df, col, top_n)\n",
    "    words, counts = zip(*top_words)\n",
    "\n",
    "    freq_df = pd.DataFrame({'Word': words, 'Frequency': counts})\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='Frequency', y='Word', data=freq_df, palette='viridis')\n",
    "    plt.title(f'Top {top_n} Most Frequent Words')\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('Words')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_frequent_words(teen_mental_health_df, 'cleaned_user_input', top_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "WxSgtAfB9aNQ",
    "outputId": "fea46fba-b68a-4ed3-bb04-d3dfff608530"
   },
   "outputs": [],
   "source": [
    "plot_frequent_words(teen_mental_health_df, 'cleaned_bot_response', top_n=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i5jc0fEdDNXY",
    "outputId": "354a2e35-bdd3-4ac8-9c9f-a3185b90e052"
   },
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures, TrigramAssocMeasures\n",
    "\n",
    "\n",
    "all_tokens = []\n",
    "for text in teen_mental_health_df['cleaned_user_input']:\n",
    "    all_tokens.extend(word_tokenize(text))\n",
    "\n",
    "\n",
    "bigram_finder = BigramCollocationFinder.from_words(all_tokens)\n",
    "top_bigrams = bigram_finder.nbest(BigramAssocMeasures.likelihood_ratio, 10)\n",
    "\n",
    "\n",
    "trigram_finder = TrigramCollocationFinder.from_words(all_tokens)\n",
    "top_trigrams = trigram_finder.nbest(TrigramAssocMeasures.likelihood_ratio, 10)\n",
    "\n",
    "print(\"Top Bigrams (Collocation):\", top_bigrams)\n",
    "print(\"Top Trigrams (Collocation):\", top_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yBwUmx8qIJnU",
    "outputId": "94b45795-726d-46b1-d2dc-3c76e59f3c9b"
   },
   "outputs": [],
   "source": [
    "# Create an NLTK Text object\n",
    "text_obj = nltk.Text(all_tokens)\n",
    "\n",
    "# Show concordance for a keyword (e.g., 'feel')\n",
    "print(text_obj.concordance(\"friend\", width=60, lines=10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCL7t4HgbAf_"
   },
   "source": [
    "# **Sentiment Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjbOmSxN68uI"
   },
   "source": [
    "# Sentiment Analysis Using Vader\n",
    "* Uses a bag of words approach\n",
    "* It gives a compound score , negative , positive and neutral scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bXCU9iL9Z5FH"
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "teen_mental_health_df['user_sentiment'] = teen_mental_health_df['cleaned_user_input'].apply(lambda x: analyzer.polarity_scores(x)['compound']>0 and 'Positive' or analyzer.polarity_scores(x)['compound']<0 and 'Negative' or 'Neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D_m6HM_HbJcI",
    "outputId": "f2b5c568-43f0-4de1-dfa0-426b7a784dce"
   },
   "outputs": [],
   "source": [
    "print(teen_mental_health_df['user_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "KEGoSUmwI2rJ",
    "outputId": "14aaa348-4799-48ff-ddc9-edf6df74c3c2"
   },
   "outputs": [],
   "source": [
    "teen_mental_health_df.groupby('user_sentiment')['user_input'].count().plot(kind='bar', color=sns.palettes.mpl_palette('Dark2'))\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of User Sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87,
     "referenced_widgets": [
      "8cd7dcc7189344d5ad5e8b2e90dd99ef",
      "7dfbe33abee5459abd307b6149d085db",
      "1c777632b60b4fefa80eaed628b6a10b",
      "39269f4c65594adc961a0bdb4a9f1601",
      "8e478702306d4d24b2f2aedb33ee2dff",
      "0a62b4003d8645898bf6f601ccbb3fda",
      "b385d018585744fca04a3734ab6e9f44",
      "df8b5164ace142e1921ca9a97036a154",
      "3c023081e69c4dab95ecb720cf5fae1b",
      "c69c98a874c9444ca388538a7a1bac0c",
      "6e507ab909b14f3595bb1945b1811d77"
     ]
    },
    "id": "CDbHcLL9bOrI",
    "outputId": "c0db5255-14f1-428c-98fe-58319c4f35df"
   },
   "outputs": [],
   "source": [
    "res = {}\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for i, row in tqdm(teen_mental_health_df.iterrows(), total=len(teen_mental_health_df)):\n",
    "    try:\n",
    "        text = row['cleaned_bot_response']\n",
    "        res[i] = analyzer.polarity_scores(text)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ahT60nBpMaIj",
    "outputId": "f1147f66-14c5-47d6-dfe6-b685aef5d756"
   },
   "outputs": [],
   "source": [
    "vaders_df = pd.DataFrame.from_dict(res, orient='index')\n",
    "teen_mental_health_df = teen_mental_health_df.join(vaders_df,how='left')\n",
    "print(teen_mental_health_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "UNLAPQMeM6B0",
    "outputId": "ea418555-a367-4137-a1a8-3b5ff3b5cdcc"
   },
   "outputs": [],
   "source": [
    "ax=sns.barplot(data=teen_mental_health_df,x='user_sentiment',y='compound')\n",
    "ax.set_title('Compound Sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "5vkL9rr8Nk4a",
    "outputId": "ed23639e-a708-461a-ac95-9926702b0786"
   },
   "outputs": [],
   "source": [
    "fig,axs=plt.subplots(1,3,figsize=(15,5))\n",
    "sns.histplot(vaders_df['pos'],ax=axs[0])\n",
    "sns.histplot(vaders_df['neg'],ax=axs[1])\n",
    "sns.histplot(vaders_df['neu'],ax=axs[2])\n",
    "axs[0].set_title('Positive')\n",
    "axs[1].set_title('Negative')\n",
    "axs[2].set_title('Neutral')\n",
    "plt.tight_layout()\n",
    "plt.savefig('sentiment.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25I5dNMdfE-x"
   },
   "source": [
    " 1. **Positive Sentiment Distribution**\n",
    "> Most scores are between 0.0 and 0.2, indicating that the majority of bot responses have low positivity.\n",
    "\n",
    "> A small number of responses have scores above 0.6, suggesting some strongly positive messages, but they are relatively rare.\n",
    "\n",
    " **Interpretation**:\n",
    "* The bot generally maintains a low-key supportive tone\n",
    "* It responds with few highly enthusiastic or cheerful messages — possibly to remain empathetic rather than overly cheerful.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    " 2. **Negative Sentiment Distribution**\n",
    "> A large peak at 0.0–0.1: most responses have very low negativity.\n",
    "\n",
    "> Only a few responses exceed 0.4–0.5, and almost none go beyond 0.7.\n",
    "\n",
    " **Interpretation**:\n",
    "`The chatbot is carefully avoiding negative language, which is expected and appropriate in mental health contexts.`\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "3. **Neutral Sentiment Distribution**\n",
    "> The scores are more evenly spread, with a peak around 0.5, and many values between 0.3 to 0.7.\n",
    "\n",
    "> Some responses are highly neutral (0.9–1.0) — possibly more factual or non-emotional.\n",
    "\n",
    "**Interpretation**:\n",
    "`The chatbot responses are primarily neutral in tone, which aligns with maintaining balance, objectivity, and emotional safety during mental health conversations.`\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Sentiment\tKey Insights**\n",
    "1. **Negative** : \tMost responses are non-negative, as expected in a supportive context.\n",
    "2. **Neutral**: \tThe chatbot relies heavily on neutral language, which is often seen in calming or informational responses.\n",
    "3. **Positive\tPositivity** is present but generally mild — the bot avoids sounding overly upbeat, possibly to stay relatable.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwYyeJyj69Ru"
   },
   "source": [
    "> One issue with vader sentiment analyzer is that it doesn't take context into account\n",
    "\n",
    "> So we will compare vaders result to Roberta Pre Trained model which accounts for context too ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JNs3X43udk01"
   },
   "source": [
    "# Using Roberta For Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dcjg6Hyx65LQ"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHOD0BDS8pbL"
   },
   "outputs": [],
   "source": [
    "def polarity_scores_roberta(example):\n",
    "    encoded_text=tokenizer(example,return_tensors='pt')\n",
    "    output=model(**encoded_text)\n",
    "    scores=output[0][0].detach().numpy()\n",
    "    scores=softmax(scores)\n",
    "    scores_dict={\n",
    "        'roberta_neg':scores[0],\n",
    "        'roberta_neu':scores[1],\n",
    "        'roberta_pos':scores[2]\n",
    "    }\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669,
     "referenced_widgets": [
      "720916bb9e1e4651bac9f8ff63f83cd6",
      "379e2a2aacfa45c7a0c3e5d49894fe48",
      "09a24469cb314c71ac875e10bcafe20b",
      "bbbc4986f26c4e318dfc9aa06bf5a3d2",
      "0560f7f62e59462d84c3e05111cefeaa",
      "b9219846c77242deaab2122858f30eb0",
      "30ce637890be4ca79453db2a1c3df72e",
      "bea98664bdab4e10900d81b1e9b18d4d",
      "a3ebfc1d26f14f9fb82c61c38d3194b9",
      "f1d35cdd7a9046d090ea4a16ee0da108",
      "3b98f42f5d1543e3b01ec0fba8f9b2b7"
     ]
    },
    "id": "zeE0jewo9kKw",
    "outputId": "7d35e7da-99f5-4562-c101-995d2ca573cd"
   },
   "outputs": [],
   "source": [
    "for i,row in tqdm(teen_mental_health_df.iterrows(),total=len(teen_mental_health_df)):\n",
    "    try:\n",
    "        text=row['cleaned_bot_response']\n",
    "        roberta_result=polarity_scores_roberta(text)\n",
    "        for key,value in roberta_result.items():\n",
    "            teen_mental_health_df.loc[i,key]=value\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "print(teen_mental_health_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "atKLOVVr_JM7",
    "outputId": "728b48ec-1f00-46ea-cc10-2c6b1b437870"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data=teen_mental_health_df,vars=['neg','neu','pos','roberta_neg','roberta_neu','roberta_pos'],hue='user_sentiment',palette='tab10')\n",
    "plt.savefig('Roberta_Vs_Vader.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JT9zCtaGwe2"
   },
   "source": [
    "***Key Inferences from the Plot***\n",
    "1. **VADER vs RoBERTa Distributions**\n",
    "\n",
    "> VADER scores (neg, neu, pos) are mostly well spread and mutually exclusive (neg vs pos shows a clear inverse relationship).\n",
    "\n",
    "> RoBERTa scores are more concentrated and less sharply defined — more probabilistic than rule-based VADER.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "2. **Diagonal KDE plots**\n",
    "\n",
    "`The diagonal plots show density distributions of each sentiment score`:\n",
    "\n",
    "* VADER pos has a wide distribution, with Positive-labeled points peaking at higher values.\n",
    "\n",
    "* RoBERTa pos shows a narrow, steep spike: it's more confident and binary, which is typical of deep learning models.\n",
    "\n",
    "* VADER neu is flatter; RoBERTa neu shows sharper bimodality — may reflect stronger neutral decisions.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "3. **Off-Diagonal Scatter Plots**\n",
    " > **neg vs pos and roberta_neg vs roberta_pos**:\n",
    "\n",
    "* Clearly negatively correlated, as expected — when negative is high, positive is low.\n",
    "\n",
    "* RoBERTa shows more saturation, i.e., values near 0 or 1, reflecting high model confidence.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**VADER and RoBERTa comparisons**:\n",
    "\n",
    "> VADER pos and RoBERTa pos have some agreement but are not perfectly correlated.\n",
    "\n",
    "> Similarly for neg — RoBERTa may classify strong negations more sharply than VADER.\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 506
    },
    "id": "Dx3a3cS3DKtt",
    "outputId": "2c533633-2033-47bf-d797-27ad11aaad1e"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(teen_mental_health_df[['neg', 'neu', 'pos', 'roberta_neg', 'roberta_neu', 'roberta_pos']].corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 860
    },
    "id": "HAFyrvglDfmy",
    "outputId": "4b49043f-dd3b-44c2-bd82-be6af7e4d24b"
   },
   "outputs": [],
   "source": [
    "fig,axs=plt.subplots(1,3,figsize=(15,5))\n",
    "sns.boxplot(x='user_sentiment',y='neg',data=teen_mental_health_df,ax=axs[0])\n",
    "sns.boxplot(x='user_sentiment',y='roberta_neg',data=teen_mental_health_df,ax=axs[1])\n",
    "sns.boxplot(x='user_sentiment',y='neu',data=teen_mental_health_df,ax=axs[2])\n",
    "\n",
    "axs[0].set_title('Negative')\n",
    "axs[1].set_title('Roberta Negative')\n",
    "axs[2].set_title('Neutral')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig,axs=plt.subplots(1,3,figsize=(15,5))\n",
    "sns.boxplot(x='user_sentiment',y='roberta_neu',data=teen_mental_health_df,ax=axs[0])\n",
    "sns.boxplot(x='user_sentiment',y='pos',data=teen_mental_health_df,ax=axs[1])\n",
    "sns.boxplot(x='user_sentiment',y='roberta_pos',data=teen_mental_health_df,ax=axs[2])\n",
    "axs[0].set_title('Roberta Neutral')\n",
    "axs[1].set_title('Positive')\n",
    "axs[2].set_title('Roberta Positive')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEcK23reHKEy"
   },
   "source": [
    "1. **VADER Negative (neg)**\n",
    "\n",
    "> `Median neg score is higher for user-labeled Negative responses compared to others`.\n",
    "\n",
    "> `But some Positive-labeled responses also have high neg scores → VADER can misclassify certain emotional language.`\n",
    "\n",
    "> `Distribution overlaps across all labels → moderate separation.`\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "2. **RoBERTa Negative (roberta_neg)**\n",
    "\n",
    "> `Clearer separation than VADER`:\n",
    "\n",
    "> `Highest medians for Negative-labeled data.`\n",
    "\n",
    "> `Positive and Neutral have much lower scores with tighter ranges.`\n",
    "\n",
    "> `Outliers for Positive and Neutral → some misclassifications, but generally well-separated.`\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "*  **Inference**: `RoBERTa is more confident and effective at detecting negative sentiment than VADER.`\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "3. **VADER Neutral (neu)**\n",
    "\n",
    "> `All sentiment classes have similarly high neu scores.`\n",
    "\n",
    "> `Median values are tightly clustered → VADER overuses neutral scores, making it less discriminative.`\n",
    "\n",
    "**Issue:** VADER may over-rely on neutrality, especially in emotionally complex messages.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "4. **RoBERTa Neutral (roberta_neu)**\n",
    "\n",
    "> `Still shows some overlap, but better spread across sentiment classes.`\n",
    "\n",
    "> `Slightly lower median for Positive compared to Negative and Neutral.`\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "* **Inference:** `RoBERTa neutral scores are more balanced and offer slightly better class differentiation than VADER.`\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "5. **VADER Positive (pos)**\n",
    "\n",
    "> `Positive-labeled responses have higher pos scores than others, as expected.`\n",
    "\n",
    "> `However, overlap remains — Negative and Neutral responses also show non-negligible pos scores.`\n",
    "\n",
    "> `VADER may detect surface-level positivity (e.g., “I’m okay”) even in negative contexts.`\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "6. **RoBERTa Positive (roberta_pos)**\n",
    "\n",
    "> `Excellent separation`\n",
    "\n",
    "> `Positive-labeled responses have very high positive scores.`\n",
    "\n",
    "> `Negative and Neutral have low medians, especially Negative.`\n",
    "\n",
    "> `Few outliers in Negative → minimal noise.`\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "* **Inference**: `RoBERTa is highly confident and effective at recognizing positive sentiment.`\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQjEpPtYdah5"
   },
   "source": [
    "# Final Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zBhzZKCSjYu"
   },
   "source": [
    "**Part 1: Mental Health of teenagers\n",
    "Using sentiment analysis (VADER + RoBERTa) on children's user_input, we can draw the following inferences**:\n",
    "\n",
    " 1. *Predominantly Neutral or Negative Tone*\n",
    "\n",
    "`Many inputs were classified as neutral or negative, indicating`:\n",
    "\n",
    "> A sense of emotional numbness, confusion, or resignation\n",
    "\n",
    "> Presence of stress, sadness, anxiety, or loneliness\n",
    "\n",
    "> High neutrality can also mean they mask emotions or use non-expressive language, which is common in adolescents dealing with mental stress.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "2. *Subtle Positive Inputs*\n",
    "\n",
    "> Fewer inputs had strong positive sentiment.\n",
    "\n",
    "> Even “I'm fine” or “okay” might be false positives, as emotionally distressed users often understate their feelings.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "3. *Topics of Concern (from Bigrams/Trigrams)*\n",
    "`A phrase frequency analysis (like \"feel alone\", \"no friends\", \"not happy\"), it likely reinforces`:\n",
    "\n",
    "> Social isolation\n",
    "\n",
    "> Academic or parental pressure\n",
    "\n",
    "> Identity or mental health struggles\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Conclusion**: Many children in the dataset show low or mixed emotional valence, consistent with symptoms of emotional suppression, depression, or mild to moderate distress.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Part 2: Effectiveness of Bot Responses\n",
    "The bot's responses were analyzed using VADER and RoBERTa . Here's what we can infer**:\n",
    "\n",
    "1. *Responses Skew Heavily Neutral*\n",
    "\n",
    "> Most bot responses have high neutral scores and low negative scores, which is good for avoiding harm but may seem robotic or impersonal.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "2. *Moderate Positive Sentiment*\n",
    "\n",
    "> Some responses are gently positive, which is helpful — bots should aim for empathetic encouragement, not toxic positivity.\n",
    "\n",
    "> RoBERTa identified a few strongly positive responses — this suggests the bot does try to uplift the user, but selectively.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "3. *Lack of Deep Emotional Mirroring*\n",
    "\n",
    "`If users are expressing genuine distress (as shown by negative or neutral inputs), the bot's overly-neutral replies may feel emotionally mismatched.`\n",
    "\n",
    "> Good therapy bots often use mirroring + validating language like:\n",
    "\n",
    "`“That sounds really difficult. I'm here with you.”`\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Conclusion**:\n",
    "`The bot is safe and non-triggering, but could be improved by':\n",
    "\n",
    "> Using slightly more empathetic language\n",
    "\n",
    "> Offering active listening cues or follow-up prompts\n",
    "\n",
    "> Matching the emotional tone of user inputs more closely\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
